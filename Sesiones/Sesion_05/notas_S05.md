# Material de Referencia: Dilemas √âticos y Gobernanza en IA    

---

## üåê **Temas Cubiertos**  
1. Manipulaci√≥n de narrativas mediante IA y redes sociales  
2. Alineaci√≥n empresa-gobierno en vigilancia masiva (caso Palantir)  
3. Filtros de contenido y sesgos en LLMs/Chatbots  
4. Mecanismos contra alucinaciones en IA  

---

## 1. Manipulaci√≥n de Narrativas  
### Caso de Estudio: Elon Musk y Twitter/X  
**C√≥mo funciona:**  
- Uso de algoritmos de recomendaci√≥n para priorizar contenido "anti-woke"  
- Despriorizaci√≥n de cuentas cr√≠ticas mediante shadow banning  
- Bots que amplifican mensajes clave  

**Conceptos clave:**  
- **C√°mara de eco algor√≠tmica**: Sistemas que refuerzan creencias existentes  
- **Microtargeting**: Publicidad pol√≠tica ultra-personalizada  

**Material de apoyo:**  
- [Twitter Files - Documentos internos sobre moderaci√≥n](https://twitterfiles.com)   
- [Platform Manipulation in 2023](https://www.rand.org/content/dam/rand/pubs/perspectives/PEA2600/PEA2679-1/RAND_PEA2679-1.pdf)
- [C√≥mo Elon Musk destruy√≥ Twitter y c√≥mo salvarlo](https://www.washingtonpost.com/es/post-opinion/2023/01/02/elon-musk-twitter-encuesta-periodistas/)
- [The Hill & Valley Forum](https://www.youtube.com/@HillValleyForum)
- [Forging the Technological Republic](https://www.youtube.com/live/uQCazCId_9o?si=FzwXM4817BtZIo0f&t=4790)

---

## 2. Empresas de IA y Gobiernos  
### Caso Palantir (Vigilancia Masiva)  
**Operaciones clave:**  
- An√°lisis predictivo para identificar "amenazas" (ej: protestas)  
- Integraci√≥n con datos de tel√©fonos, redes sociales y reconocimiento facial  

**Dilema √©tico:**  
- ¬øDeben las empresas rechazar contratos con gobiernos autoritarios?  

**Recursos:**  
- [Informe Amnesty sobre Palantir](https://doc.es.amnesty.org/ms-opac/doc?q=norm%3Asiai+AND+media%3Atrue+AND+msstored_doctype%3ADocumentaci%C3%B3n&start=3371&rows=1&sort=fecha%20asc&fq=norm&fv=*&fo=and) 
- [Contratos con ICE (EE.UU.)](https://www.lanacion.com.ar/estados-unidos/migraciones/immigrationos-asi-funciona-el-nuevo-software-para-rastrear-migrantes-para-ice-nid10052025/)
- [Palantir CEO Alex Karp and Jacob Helberg | Hill & Valley Forum 2024](https://www.youtube.com/watch?app=desktop&v=MqXQFfCIOiA)
- [There have been 500 days genocide and Palantir is responsible for killig innocent civilians in Gaza](https://youtu.be/RPQFWWXrEJc?si=w7v6Ew7ybdL80rIo)
- [Viral Palantir protester warns all complicit in Gaza horrors](https://www.aa.com.tr/en/middle-east/interview-expose-them-viral-palantir-protester-warns-all-complicit-in-gaza-horrors/3565328)
- [Palantir allegedly enables Israel's AI targeting in Gaza, raising concerns over war crimes](https://www.business-humanrights.org/es/%C3%BAltimas-noticias/palantir-allegedly-enables-israels-ai-targeting-amid-israels-war-in-gaza-raising-concerns-over-war-crimes/)
- [Palantir allegedly supplying Israel with AI tools amid Israel's war in Gaza](https://www.business-humanrights.org/es/%C3%BAltimas-noticias/palantir-allegedly-supplying-israel-with-ai-tools-amid-israels-war-in-gaza/)
- [Palantir CEO Alex Karp on college protests and the future of war](https://youtu.be/E1schQrqJFU?si=HuvE9Whhmovbmvnu)
- [ICE firma contrato de $30M con Palantir para tecnolog√≠a de datos](https://www.visaverge.com/es/noticias/ice-firma-contrato-de-30m-con-palantir-para-tecnologia-de-datos/)
- [InmigrationOS, la tecnolog√≠a de vigilancia que Trump ha encargado a Palantir para monitorizar inmigrantes: ‚ÄúPretende un control absoluto‚Äù](https://elpais.com/tecnologia/2025-04-25/inmigrationos-la-tecnologia-de-vigilancia-que-trump-ha-encargado-a-palantir-para-monitorizar-inmigrantes-pretende-un-control-absoluto.html)
- [El ICE y Palantir desarrollar√°n una nueva tecnolog√≠a de IA para identificar a inmigrantes en EE UU](https://es.wired.com/articulos/ice-y-palantir-desarrollaran-nueva-tecnologia-para-identificar-a-inmigrantes-en-ee-uu)
- [Palantir se vuelve hostil contra periodistas por la cobertura sobre su relaci√≥n con el gobierno de Trump](https://es.wired.com/articulos/palantir-se-vuelve-hostil-contra-periodistas-por-la-cobertura-sobre-su-relacion-con-el-gobierno-de-trump)
- [The Hill & Valley Forum 2025: Rebuilding America](https://www.youtube.com/live/uQCazCId_9o?si=mhW_Oq4AJ6dIRXcZ)
- [Palantir CEO Alex Karp & Rep. Ritchie Torres on Innovation & The West](https://youtu.be/DEZCBkn20Og?si=fSQ06YQ06FHrHY1z)
- [What is a long context window?](https://blog.google/technology/ai/long-context-window-ai-models/#:~:text=Previously%2C%20Gemini%20could%20process%20up,can%20take%20in%20and%20process.)

---

## 3. Filtros y Sesgos en Chatbots  
### Enfoques t√©cnicos:  
| Empresa   | M√©todo de Filtrado | Ejemplo de Sesgo |  
|-----------|--------------------|------------------|  
| OpenAI    | Checklist post-generaci√≥n | Evita temas pol√≠ticos |  
| Google    | Dataset filtrado pre-entrenamiento | Sobrecorrecci√≥n "woke" |  
| Meta      | Modelo de moderaci√≥n separado | Errores con dialectos |  

Los filtros de *political correctness* son mecanismos que limitan o moderan las respuestas de los modelos de lenguaje para evitar contenido ofensivo, discriminatorio o pol√≠ticamente sensible. Estos filtros se implementan por razones √©ticas, legales y comerciales.

---

### 1. [Hablemos de Chatbots](https://www.youtube.com/watch?v=aQf9kzb_3ng)

- Los chatbots no son conscientes, pero pueden generar contenido sensible si no se filtra.
- Las empresas como OpenAI y Microsoft implementan APIs y capas de moderaci√≥n para evitar que respondan sobre violencia, pol√≠tica extrema o contenido sexual.
- Estas limitaciones pueden afectar la autenticidad y utilidad del chatbot en ciertos contextos.

---

### 2. [¬øC√≥mo funcionan los chatbots?](https://www.youtube.com/watch?v=Fw9tWZOraUo)

- Los modelos aprenden de datos p√∫blicos y luego se ajustan con reglas para evitar sesgos.
- Los filtros pueden limitar la expresi√≥n libre, pero tambi√©n protegen contra desinformaci√≥n y discurso de odio.
- Los moderadores humanos complementan el sistema para bloquear respuestas ofensivas.

---

### 3. [El renacer de los chatbots en la era de la IA Generativa](https://www.youtube.com/watch?v=z1SBcWzcpY0)

- Existe una tensi√≥n entre creatividad y seguridad, y los filtros pueden bloquear respuestas √∫tiles en arte o filosof√≠a.
- Los modelos modernos detectan intenci√≥n y contexto, no solo palabras prohibidas.
- Se debate si los filtros reflejan valores universales o intereses corporativos.

---


**Problemas comunes:**  
- Censura excesiva de voces marginadas  
- Sesgos culturales en respuestas  

**Lectura:**  
- [Fairness in Large Language Models: A Taxonomic Survey](https://arxiv.org/abs/2404.01349)
- [Corredores de datos, empresas de an√°lisis de datos, ‚Äúregistros musulmanes‚Äù y derechos humanos](https://medium.com/amnesty-insights/corredores-de-datos-empresas-de-an%C3%A1lisis-de-datos-registros-musulmanes-y-derechos-humanos-d0be38295a29)

---

## 4. Alucinaciones en IA  
### ¬øPor qu√© ocurren?  
- Falta de grounding en datos reales  
- Sobreconfianza en patrones estad√≠sticos  

**Soluciones implementadas:**  
- **OpenAI**: RAG (Retrieval-Augmented Generation)  
- **Anthropic**: Constitutional AI (reglas expl√≠citas)  

**Ejemplo did√°ctico:**  
> "ChatGPT inventa referencias acad√©micas porque 'aprende' que debe citar fuentes, sin verificar su existencia"  

---

# üß† ¬øQu√© son los filtros de correcci√≥n pol√≠tica en IA?

Los filtros de correcci√≥n pol√≠tica en IA son herramientas necesarias para evitar da√±os, pero generan debates sobre censura, libertad de expresi√≥n y sesgo institucional. Su implementaci√≥n var√≠a seg√∫n la empresa, el pa√≠s y el tipo de aplicaci√≥n.

---


## üé• **Diapositivas Resumen (Canva)**  

1. Portada con t√≠tulo  
2. Infograf√≠a "Flujo de manipulaci√≥n en redes"  
3. Tabla comparativa de filtros por empresa  
4. Diagrama simple "C√≥mo se generan alucinaciones"  
5. Casos pr√°cticos para debate  

---

## üí° Gu√≠a para la Sesi√≥n  
**Minutos 0-15:** Presentar casos Elon/Palantir  
**Minutos 15-30:** Explicar filtros y sesgos (usar tabla)  
**Minutos 30-45:** Debate sobre alucinaciones  
**Minutos 45-60:** Q&A con votaci√≥n en vivo (ej: "¬øDeben regularse los LLMs?")  

**Material adicional:**  
- [Gu√≠a √©tica de la UNESCO](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics) 

--- 

# [El Fin de la Ley de Moore para la IA: ¬øPor Qu√© los Ejecutivos de IA Est√°n Aterrados?](https://www.youtube.com/watch?v=VhLeHvouPWs)

El video, presentado por Spencer de STARTUP HAKK, aborda un cambio crucial en el panorama de la inteligencia artificial: el fin de la suposici√≥n de que los costos de la IA disminuir√°n perpetuamente, una idea a menudo comparada con la Ley de Moore. Este cambio se evidencia con el reciente aumento de precios de Google para su modelo Gemini Flash.

## Puntos Clave del Video:

### 1. Aumento de Precios de Google y el Fin de la Tendencia
* **Precedente:** Google duplic√≥ el precio de entrada de tokens de su modelo Gemini 2.5 Flash (de $0.15 a $0.30 por mill√≥n de tokens) y cuadruplic√≥ el precio de salida (de $0.60 a $2.50 por mill√≥n de tokens). Esta es la primera vez que un proveedor importante de IA aumenta los precios de un modelo establecido, marcando un punto de inflexi√≥n.

### 2. La Realidad de los Costos Cuadr√°ticos de la IA
* **Escalado no lineal:** El presentador explica que los costos de procesamiento de la IA no escalan linealmente, sino **cuadr√°ticamente** con la longitud de la secuencia. Esto significa que si la longitud de entrada de un modelo se duplica, el costo de procesamiento se cuadruplica. Los proveedores de API han estado cobrando una tarifa plana por token, mientras que sus costos operativos reales aumentaban exponencialmente.

### 3. El Fin de los Subsidios
* **Quema de efectivo:** Las grandes empresas de IA han estado subsidiando los precios de sus servicios, quemando efectivo con la esperanza de alcanzar futuras econom√≠as de escala.
* **L√≠mites f√≠sicos:** Este modelo de subsidio est√° llegando a su l√≠mite debido a limitaciones f√≠sicas y de hardware, como los altos costos de energ√≠a de los centros de datos y las limitaciones en el ancho de banda de la memoria de los chips de IA.

### 4. Cambio Estrat√©gico Hacia el Procesamiento por Lotes
* **L√≠mite de inferencia en tiempo real:** Dado que la inferencia de IA en tiempo real ha alcanzado un l√≠mite de costos, el procesamiento por lotes (procesar tareas en grupos en lugar de una por una) se vuelve mucho m√°s atractivo.
* **Ahorros significativos:** Se pueden lograr ahorros de costos de hasta el 90% al procesar tareas en lotes en servidores locales en lugar de depender de APIs en tiempo real de terceros.

### 5. La Importancia de los Modelos de C√≥digo Abierto y el Control de Datos
* **Alternativa rentable:** Se recomienda el uso de modelos de c√≥digo abierto (como los disponibles en plataformas como Olama), ya que ofrecen un rendimiento equivalente o superior a una fracci√≥n del costo, eliminando la dependencia de un √∫nico proveedor.
* **Soberan√≠a de datos:** Mantener los datos y los modelos en servidores propios permite a las empresas retener el control total de su informaci√≥n, un aspecto crucial para la seguridad y la privacidad.

### 6. L√≠mites Fundamentales de los LLMs
* **Restricciones f√≠sicas y de datos:** El video destaca que los modelos de lenguaje grandes (LLM) est√°n alcanzando l√≠mites fundamentales debido a restricciones f√≠sicas en el ancho de banda de la memoria y a la escasez de datos de entrenamiento de alta calidad.
* **"Colapso del modelo":** Entrenar con datos sint√©ticos o repetidos puede llevar al "colapso del modelo", donde el rendimiento del LLM se degrada significativamente.

### 7. Implicaciones Cr√≠ticas para las Empresas
* **Gesti√≥n de costos:** Las empresas ya no pueden asumir que los costos de la IA disminuir√°n. Los gerentes de producto y l√≠deres de TI deben integrar la gesti√≥n de costos como una caracter√≠stica principal en sus estrategias de IA.
* **Inversi√≥n en infraestructura:** Las empresas deben considerar invertir en arquitecturas de procesamiento por lotes y en infraestructura para modelos de c√≥digo abierto para optimizar costos y mantener el control.

Spencer, a trav√©s de Starter Pack, ofrece servicios de desarrollo de software y consultor√≠a para ayudar a las empresas a navegar por estos cambios, enfoc√°ndose en la conexi√≥n de sistemas y la creaci√≥n de agentes de IA personalizados.
