# Curso: IntroducciÃ³n a la Inteligencia Artificial y su Impacto en la Sociedad  
## ğŸ§  SesiÃ³n 2 â€“ Historia y taxonomÃ­a de la IA: de la cibernÃ©tica a la explosiÃ³n algorÃ­tmica

### Objetivo de la sesiÃ³n  
Explorar el desarrollo histÃ³rico de la inteligencia artificial y comprender sus principales clasificaciones funcionales y algorÃ­tmicas. Se busca situar los avances actuales dentro de un contexto tÃ©cnico, cultural y cientÃ­fico, atendiendo a sus giros ideolÃ³gicos y aceleraciones recientes.

---

## ğŸ“œ I. VisiÃ³n histÃ³rica: de los pioneros a los modelos actuales

### 1. Los fundamentos: Turing, Wiener y la cibernÃ©tica

- **Alan Turing (1912â€“1954)** propuso en 1950 la pregunta: *"Â¿Pueden las mÃ¡quinas pensar?"* Su experimento mental â€”la **Prueba de Turing**â€” estableciÃ³ una vara medible para la simulaciÃ³n conversacional.
- **Norbert Wiener (1894â€“1964)** fundÃ³ la **CibernÃ©tica**, estudiando **sistemas autorregulados** mediante retroalimentaciÃ³n. Influido por su colega **Arturo Rosenblueth**, definiÃ³ la inteligencia como adaptaciÃ³n teleolÃ³gica.
- Ambos establecieron una visiÃ³n de la IA centrada en la interacciÃ³n entre **informaciÃ³n, control y comportamiento** en contextos fÃ­sicos y sociales.

---

### 2. IA clÃ¡sica y el invierno simbÃ³lico

En los aÃ±os 60, Marvin Minsky â€”junto con Seymour Papertâ€” jugÃ³ un papel crucial en definir los lÃ­mites y posibilidades de la inteligencia artificial temprana, especialmente a travÃ©s de su anÃ¡lisis del perceptrÃ³n. El perceptrÃ³n, propuesto inicialmente por Frank Rosenblatt, era un modelo de red neuronal simple que prometÃ­a emular ciertas capacidades cognitivas humanas, como el reconocimiento visual. En ese momento, las expectativas eran altÃ­simas: se pensaba que las mÃ¡quinas podrÃ­an aprender a ver, razonar y actuar como humanos en cuestiÃ³n de dÃ©cadas.

Sin embargo, en 1969, Minsky y Papert publicaron Perceptrons: An Introduction to Computational Geometry, una obra que, aunque rigurosa y matemÃ¡tica, tuvo un efecto desalentador en el campo. En ella demostraron que los perceptrones de una sola capa no podÃ­an resolver problemas simples como la funciÃ³n XOR, lo que evidenciÃ³ limitaciones fundamentales en ese enfoque de redes neuronales. Su crÃ­tica no era un rechazo absoluto al aprendizaje automÃ¡tico, sino una llamada a la cautela y a la necesidad de bases teÃ³ricas mÃ¡s sÃ³lidas. ParadÃ³jicamente, su trabajo fue tan influyente que desviÃ³ la atenciÃ³n de la comunidad cientÃ­fica hacia enfoques simbÃ³licos de la IA durante mÃ¡s de una dÃ©cada.

En cuanto a la visiÃ³n artificial, Minsky tambiÃ©n explorÃ³ cÃ³mo las mÃ¡quinas podrÃ­an interpretar imÃ¡genes y escenas, pero siempre desde una perspectiva cognitiva mÃ¡s amplia. Su interÃ©s no era solo tÃ©cnico, sino filosÃ³fico: Â¿cÃ³mo puede una mÃ¡quina construir una representaciÃ³n del mundo? Â¿CÃ³mo puede aprender de la experiencia visual? Estas preguntas siguen vigentes hoy.

Las expectativas de la Ã©poca eran ambiciosas, incluso utÃ³picas. Se creÃ­a que en pocos aÃ±os podrÃ­amos tener mÃ¡quinas que razonen como humanos. Lo que Minsky y Papert hicieron fue poner un freno necesario, recordando que la inteligencia â€”humana o artificialâ€” es un fenÃ³meno profundamente complejo. Su legado no fue cerrar puertas, sino abrir otras mÃ¡s profundas y exigentes.

- DÃ©cada de 1950: Nace formalmente el campo de la IA en Dartmouth (McCarthy, Minsky, etc.).
- **IA simbÃ³lica** dominÃ³ durante dÃ©cadas: reglas explÃ­citas, lÃ³gica formal, motores de inferencia.
- Expectativas: lograr comprensiÃ³n, planificaciÃ³n y razonamiento similares a los humanos.
- **Primer invierno de la IA** (1970sâ€“80s): el fracaso en tareas perceptuales bÃ¡sicas desacreditÃ³ el enfoque puramente simbÃ³lico.

---
## ğŸ•°ï¸ IA en los aÃ±os 50: origen histÃ³rico, contexto social y pioneros fundacionales

La inteligencia artificial no surgiÃ³ de la nada. Su nacimiento formal en los aÃ±os 50 fue el resultado de un entrelazamiento de factores histÃ³ricos, cientÃ­ficos y culturales que marcaron profundamente la segunda mitad del siglo XX. Comprender sus raÃ­ces permite entender por quÃ© se pensÃ³ que las mÃ¡quinas podrÃ­an pensarâ€¦ y por quÃ© la promesa tardÃ³ tanto en cumplirse.

---

### ğŸŒ El contexto histÃ³rico y social

1. **Posguerra y auge tecnolÃ³gico**
   - Finalizada la Segunda Guerra Mundial, el mundo experimentÃ³ una explosiÃ³n en el desarrollo de tecnologÃ­as informÃ¡ticas, principalmente impulsadas por la necesidad militar (criptografÃ­a, radares, misiles balÃ­sticos).
   - El impacto de las primeras computadoras electrÃ³nicas (como ENIAC o Colossus) mostrÃ³ que **las mÃ¡quinas podÃ­an realizar tareas antes impensables para artefactos sin mente.**

2. **Optimismo cientÃ­fico y fe en el progreso**
   - En medio de la Guerra FrÃ­a, la ciencia era vista como la llave al dominio global.
   - Se creÃ­a que el pensamiento humano podÃ­a ser formalizado, reducido a lÃ³gica simbÃ³lica o algoritmos, y luego replicado.
   - La **cibernÃ©tica** y la **teorÃ­a de la informaciÃ³n** (Shannon, Wiener) ofrecÃ­an una estructura para comprender sistemas vivos y artificiales en tÃ©rminos de seÃ±ales, retroalimentaciÃ³n y control.

3. **Cambio filosÃ³fico y cultural**
   - La idea de que **la mente era como un sistema computacional** (la metÃ¡fora computacional de la mente) empezÃ³ a desplazar las visiones mÃ¡s humanistas de la conciencia.
   - Se popularizÃ³ la pregunta: *â€œSi el cerebro es fÃ­sico, Â¿por quÃ© no simularlo con una mÃ¡quina?â€*

---

### ğŸ§  El nacimiento formal: Conferencia de Dartmouth (1956)

En el verano de 1956, en el Dartmouth College (New Hampshire, EE. UU.), se celebrÃ³ un taller que definiÃ³ el campo emergente. El documento de propuesta decÃ­a:

> "Cada aspecto del aprendizaje o cualquier otra caracterÃ­stica de la inteligencia puede ser descrito con suficiente precisiÃ³n para que una mÃ¡quina pueda simularlo."

**Organizadores y asistentes clave:**

- **John McCarthy** (MIT y luego Stanford): acuÃ±Ã³ el tÃ©rmino â€œinteligencia artificialâ€.
- **Marvin Minsky** (MIT): neurocientÃ­fico, defensor entusiasta de la IA simbÃ³lica.
- **Claude Shannon** (Bell Labs): pionero de la teorÃ­a de la informaciÃ³n, participÃ³ brevemente.
- **Nathaniel Rochester** (IBM): desarrollador del primer compilador.
- **Allen Newell y Herbert Simon** (Carnegie Mellon): creadores del programa *Logic Theorist*, considerado el primer sistema experto.

---

### ğŸ§ª Expectativas iniciales

Los pioneros creÃ­an que el progreso serÃ­a **rÃ¡pido y transformador**:

- Que en **una o dos dÃ©cadas** las mÃ¡quinas serÃ­an capaces de razonar, aprender idiomas naturales, resolver teoremas y jugar como humanos.
- Se hablaba de **â€œmÃ¡quinas inteligentesâ€** con competencias generales en lÃ³gica, matemÃ¡ticas, lenguaje, visiÃ³n y acciÃ³n.
- Se proyectaban aplicaciones en medicina, ciencia, automatizaciÃ³n industrial y hasta filosofÃ­a.

> ğŸ§© Marvin Minsky declarÃ³ en 1970 que *â€œen tres a ocho aÃ±os tendremos una mÃ¡quina con la inteligencia general de un ser humano promedioâ€*. Esa predicciÃ³n, como muchas de la Ã©poca, resultÃ³ sobradamente optimista.

---

### ğŸ›ï¸ Instituciones pioneras

- **MIT (Massachusetts Institute of Technology)** â€“ Laboratorio de IA fundado por Minsky y Seymour Papert.
- **Stanford University** â€“ Centro clave en IA y robÃ³tica.
- **Carnegie Mellon University** â€“ Centro lÃ­der en IA aplicada y programaciÃ³n simbÃ³lica.
- **IBM Research** â€“ Inversiones en hardware y lenguajes de programaciÃ³n.
- **RAND Corporation** â€“ Vinculada al desarrollo temprano de redes neuronales artificiales y teorÃ­a de juegos.

---

### ğŸ“Œ ReflexiÃ³n histÃ³rica

Las condiciones tecnolÃ³gicas, ideolÃ³gicas y culturales de los aÃ±os 50 permitieron imaginar que â€œpensarâ€ era una funciÃ³n replicable por circuitos. El entusiasmo se basaba en una fe profunda en la capacidad de la ciencia para explicar todo â€”incluso la conciencia. Aunque muchas de las predicciones no se cumplieron en los plazos esperados, **plantaron las semillas de una de las revoluciones tecnolÃ³gicas mÃ¡s significativas del siglo XXI**.

Â¿Quieres que tambiÃ©n explore las fases posteriores como el primer â€œinvierno de la IAâ€ o cÃ³mo evolucionaron los enfoques simbÃ³licos hacia el aprendizaje estadÃ­stico?


### 3. VisiÃ³n computacional: el caso de la visiÃ³n artificial

- Desde 2010, el **ImageNet Large Scale Visual Recognition Challenge (ILSVRC)**, organizado por Stanford y Princeton, estimulÃ³ avances en reconocimiento de imÃ¡genes.
  - Dataset: >14 millones de imÃ¡genes etiquetadas.
  - Tarea: clasificar objetos en 1,000 categorÃ­as con el menor error posible.
  - Avances lentos hasta 2012 (~26% error).

- **2012 â€“ AlexNet (Hinton, Krizhevsky, Sutskever):**
  - Introduce redes profundas con GPU.
  - Error: 15%, mejorando drÃ¡sticamente el estado del arte.
  - Marca el renacimiento del **Deep Learning** como paradigma dominante.

---

### 4. AnÃ©cdotas icÃ³nicas de la nueva era

- **Ng y los gatitos (2012):**  
  - En un proyecto secreto de Google, Andrew Ng entrena una red neuronal sin supervisiÃ³n para descubrir patronesâ€¦ espontÃ¡neamente detecta caras y gatos.
  - Prueba de que las redes pueden abstraer sin etiquetado manual.

- **Traductor de Google mejora solo:**  
  - Durante aÃ±os, Google Translate se basÃ³ en reglas lingÃ¼Ã­sticas diseÃ±adas por expertos.  
  - Cuando se entrenÃ³ con tÃ©cnicas de deep learning **sin intervenciÃ³n de lingÃ¼istas**, la calidad aumentÃ³ drÃ¡sticamente.  
  - ImplicaciÃ³n: el aprendizaje de patrones estadÃ­sticos puede superar el conocimiento experto manual.

- **Sam Altman y el escepticismo de los inicios:**  
  - En OpenAI, Altman dudÃ³ inicialmente de que los modelos escalaran razonablemente.  
  - El Ã©xito inesperado de GPT y Codex lo llevÃ³ a reformular el rol de â€œalineaciÃ³nâ€ y gobernanza en IA.  
  - Su frase en 2023: *"We don't know whatâ€™s next, but the curve is steeper than it looks."*

---

### 5. Juegos, estrategia y aprendizaje por refuerzo

- **IBM Deep Blue (1997):** derrotÃ³ a Garry Kasparov en ajedrez mediante bÃºsqueda bruta y heurÃ­stica, sin aprendizaje.
- **AlphaGo (DeepMind, 2016):**  
  - UsÃ³ **Reinforcement Learning** y redes neuronales profundas para vencer a campeones de Go.
  - Primer sistema en dominar un juego altamente intuitivo y estratÃ©gico.
  - La arquitectura fue luego adaptada a problemas de optimizaciÃ³n, simulaciÃ³n y predicciÃ³n.

---

## ğŸ—‚ï¸ II. TaxonomÃ­a de la IA

### A. Por grado de alcance

| CategorÃ­a             | DescripciÃ³n |
|-----------------------|-------------|
| **IA dÃ©bil (narrow AI)**     | DiseÃ±ada para tareas especÃ­ficas (ej. clasificaciÃ³n de imÃ¡genes, recomendaciÃ³n de productos). |
| **IA general (AGI)**         | Aspira a realizar cualquier tarea cognitiva que un humano pueda hacer. No existe aÃºn. |
| **IA superinteligente**      | HÃ­brido hipotÃ©tico que supera a los humanos en toda tarea relevante. Objeto de especulaciÃ³n filosÃ³fica y tÃ©cnica. |

> ğŸ’¡ Toda la IA actual es â€œestrechaâ€: incluso GPT-4 y AlphaFold no transfieren conocimiento a tareas ajenas a su diseÃ±o.

---

### B. Por enfoque algorÃ­tmico

| Enfoque                  | CaracterÃ­sticas |
|--------------------------|-----------------|
| **SimbÃ³lico (GOFAI)**          | LÃ³gica, reglas y lenguaje formal. Interpretable pero rÃ­gido. |
| **Aprendizaje automÃ¡tico**      | Aprende patrones desde datos. Requiere ajuste fino. |
| **Aprendizaje profundo**        | Redes neuronales con muchas capas (deep learning). Capaz de detectar representaciones jerÃ¡rquicas. |
| **Aprendizaje por refuerzo**    | El agente mejora su comportamiento probando acciones y midiendo recompensas. Base de AlphaGo, Codex. |
| **Neuro-simbÃ³lico**             | CombinaciÃ³n emergente que busca lo mejor de ambos mundos: razonamiento y aprendizaje flexible. |

---

### C. RelaciÃ³n IA â†” ML â†” DL

Inteligencia Artificial
â”‚
â”œâ”€â”€ Machine Learning (subcampo de IA)
â”‚   â””â”€â”€ Deep Learning (subcampo del ML)

> ğŸ“Œ Machine Learning es un subconjunto de IA, y Deep Learning (redes profundas) es a su vez una rama dentro de ML.

## ğŸš€ III. Estado del arte y expectativas
Grandes modelos lingÃ¼Ã­sticos (LLMs): capaces de codificar, razonar y traducir en lenguaje natural.

IA multimodal: combina texto, imÃ¡genes, video y audio (ej. Gemini, GPT-4-Vision).

Avances en robÃ³tica + IA: integraciÃ³n creciente en tareas fÃ­sicas controladas por algoritmos entrenados.

Alineamiento Ã©tico: tema crÃ­tico en entornos abiertos. Se investigan marcos normativos, supervisiÃ³n humana y explicabilidad.

> ğŸ”­ Se espera que la IA se especialice aÃºn mÃ¡s, con modelos mÃ¡s eficientes y regulaciones mÃ¡s estrictas. La â€œAGIâ€ sigue siendo un horizonte abierto y polÃ©mico.

## ğŸ“ Cierre y reflexiÃ³n
Â¿QuÃ© visiÃ³n histÃ³rica o tecnolÃ³gica resonÃ³ mÃ¡s contigo?

Â¿Es la IA un proceso evolutivo predecible o un salto cualitativo inesperado?

Â¿DeberÃ­a una IA tener lÃ­mites definidos por su diseÃ±o o adaptarse mÃ¡s allÃ¡ de lo previsto?

## ğŸ¥ Recurso recomendado
Documental: AlphaGo: The Movie (DeepMind, 2017) 

Video corto: "Â¿QuÃ© es y cÃ³mo funciona la inteligencia artificial?" â€“ EDteam ğŸ“ https://www.youtube.com/watch?v=tA5cinvOU8
