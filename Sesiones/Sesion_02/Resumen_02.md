# üß† Resumen Ejecutivo ‚Äì Sesi√≥n 2
Historia y taxonom√≠a de la IA: de la cibern√©tica a la explosi√≥n algor√≠tmica

## üéØ Objetivo de la sesi√≥n
Comprender el desarrollo hist√≥rico y filos√≥fico de la inteligencia artificial (IA), identificar sus principales categor√≠as funcionales y algor√≠tmicas, y reconocer los hitos culturales, t√©cnicos e institucionales que marcaron su evoluci√≥n.

## üï∞Ô∏è I. Trayectoria hist√≥rica de la IA
Pioneros y contexto fundacional (d√©cadas 1940‚Äì1950)
Alan Turing propuso la idea de una m√°quina que piense, introduciendo la prueba de Turing (1950).

Norbert Wiener, junto con Arturo Rosenblueth, desarroll√≥ la cibern√©tica: estudio de sistemas que se autorregulan mediante retroalimentaci√≥n.

El surgimiento de la IA estuvo vinculado a avances t√©cnicos de posguerra, optimismo cient√≠fico y la met√°fora computacional de la mente.

Conferencia de Dartmouth (1956)
Marca el inicio formal del campo de la IA.

Principales figuras: John McCarthy, Marvin Minsky, Claude Shannon, Herbert Simon, Allen Newell.

Expectativas: lograr razonamiento autom√°tico, comprensi√≥n del lenguaje, planificaci√≥n, e incluso conciencia artificial en pocas d√©cadas.

## ‚ùÑÔ∏è II. IA simb√≥lica y sus l√≠mites
Predomin√≥ por d√©cadas: reglas l√≥gicas, motores de inferencia, representaciones simb√≥licas.

Minsky y Papert (1969) demostraron las limitaciones de los perceptrones (modelo neuronal simple), frenando el entusiasmo por las redes neuronales.

Primer invierno de la IA (a√±os 70‚Äì80): desilusi√≥n ante el estancamiento t√©cnico.

## üì∏ III. Auge del aprendizaje profundo (Deep Learning)
Visi√≥n artificial y el desaf√≠o de ImageNet
ILSVRC (2010‚Äì2017): competencia impulsada por Stanford y Princeton para mejorar el reconocimiento visual.

En 2012, AlexNet (Hinton, Krizhevsky, Sutskever) introduce redes profundas con GPU ‚Üí salto cualitativo en precisi√≥n.

### An√©cdotas clave
‚ÄúLos gatitos de Ng‚Äù: red neuronal sin supervisi√≥n identifica rostros y gatos sin ser entrenada expl√≠citamente.

Google Translate mejora cuando se prescinde de expertos ling√ºistas y se entrenan modelos con grandes corpus.

Sam Altman (OpenAI): pas√≥ de esc√©ptico a promotor clave tras el √©xito inesperado de modelos de lenguaje.

## ‚ôüÔ∏è IV. Reinforcement Learning y dominio de juegos
IBM Deep Blue (1997) derrota a Kasparov con fuerza bruta + heur√≠stica.

AlphaGo (DeepMind, 2016) vence a campeones de Go combinando redes profundas y reinforcement learning.

Abre camino a la IA como herramienta de toma de decisiones adaptativas.

## üß≠ V. Taxonom√≠a de la IA
### A. Seg√∫n alcance o capacidad
| Tipo de IA             | Descripci√≥n                                                                 |
|------------------------|------------------------------------------------------------------------------|
| **Estrecha (narrow)**  | Tareas espec√≠ficas (ej. traducci√≥n autom√°tica, recomendaci√≥n de productos).  |
| **General (AGI)**      | Capacidad cognitiva similar a la de un ser humano (a√∫n hipot√©tica).          |
| **Superinteligente**   | IA hipot√©tica que supera a los humanos en todas las √°reas del conocimiento. |

### B. Seg√∫n enfoque t√©cnico
| Enfoque                   | Caracter√≠sticas                                                   |
|---------------------------|--------------------------------------------------------------------|
| **Simb√≥lico (GOFAI)**     | Reglas expl√≠citas y l√≥gica formal; alta interpretabilidad.         |
| **Aprendizaje autom√°tico (ML)** | Modelado estad√≠stico basado en datos; requiere entrenamiento supervisado o no supervisado. |
| **Aprendizaje profundo (DL)**   | Redes neuronales con muchas capas; detecta representaciones jer√°rquicas complejas.           |
| **Aprendizaje por refuerzo**    | Agentes que aprenden mediante prueba y error optimizando recompensas en un entorno.         |
| **Neuro-simb√≥lico**             | Combina estructuras simb√≥licas con redes neuronales; busca razonamiento interpretable con flexibilidad adaptativa. |

> üìå Deep Learning es un subcampo dentro del ML, que a su vez es una rama dentro de la IA.

# üß≠ Taxonom√≠a t√©cnica ampliada de la Inteligencia Artificial

Esta tabla resume c√≥mo se ubican algunos enfoques y t√©cnicas contempor√°neas dentro de la arquitectura general de la IA.

---

## üìö Clasificaci√≥n general

| Enfoque t√©cnico               | Subcategor√≠as / Ejemplos clave                                            |
|-------------------------------|----------------------------------------------------------------------------|
| **IA simb√≥lica (GOFAI)**      | Sistemas expertos, l√≥gica formal, planificaci√≥n autom√°tica                |
| **Aprendizaje autom√°tico (ML)** | Supervisado / No supervisado / Semi-supervisado                         |
| ‚Üí **Aprendizaje profundo (DL)** | CNNs (visi√≥n), RNNs (texto), Transformers                               |
|    ‚Üí **LLMs (Large Language Models)** | GPT, BERT, LLaMA, PaLM (basados en Transformers)               |
| **Aprendizaje por refuerzo (RL)** | Q-learning, SARSA, pol√≠ticas adaptativas                               |
| ‚Üí **Deep RL**                 | AlphaGo, AlphaZero, Codex, rob√≥tica aut√≥noma                             |
| **Neuro-simb√≥lico**           | Redes neuronales + reglas estructuradas; razonamiento interpretativo      |

---

## üîç Ubicaci√≥n espec√≠fica

- **LLMs (Large Language Models)**  
  - Subtipo de **Aprendizaje profundo (DL)**  
  - Usan arquitectura **Transformer**  
  - Entrenamiento auto-supervisado con grandes corpus de texto  
  - Ejemplos: GPT, Claude, BERT, LLaMA, Gemini

- **Reinforcement Learning (RL)**  
  - Enfoque distinto al aprendizaje supervisado  
  - El agente aprende por ensayo y error en un entorno din√°mico  
  - Usado en juegos, navegaci√≥n, rob√≥tica, optimizaci√≥n de procesos  
  - **Deep RL** combina RL con redes neuronales profundas para tareas complejas

---

## ü§ñ Analog√≠a conceptual

- **LLMs**: ‚ÄúAprenden leyendo libros, textos y conversaciones‚Äù ‚Üí uso masivo de texto digital
- **RL**: ‚ÄúAprende actuando y cometiendo errores‚Äù ‚Üí agente adaptativo que explora su entorno

---

# ‚öôÔ∏è ¬øQu√© es la arquitectura Transformer?

La arquitectura **Transformer** es un tipo de modelo de red neuronal profunda dise√±ado para procesar secuencias de datos (como texto, audio o c√≥digo) de forma eficiente y paralela. Se ha convertido en la **base t√©cnica dominante** para modelos de lenguaje natural como GPT, BERT, T5, LLaMA y Gemini, as√≠ como para aplicaciones en visi√≥n, traducci√≥n autom√°tica, m√∫sica, prote√≠nas y m√°s.

---

## üìú Origen: ¬øQui√©n la propuso y por qu√©?

- Fue introducida en 2017 por investigadores de Google Brain en el art√≠culo seminal titulado  
  **"Attention is All You Need"** (*Vaswani et al., 2017*).
- Su motivaci√≥n fue reemplazar arquitecturas anteriores ‚Äîcomo las redes recurrentes (RNN) y LSTM‚Äî que eran lentas y dif√≠ciles de paralelizar.

> ‚úÖ La clave de los Transformers es su mecanismo de **self-attention**, que permite al modelo enfocarse din√°micamente en distintas partes de una secuencia al mismo tiempo.

---

## üß† ¬øPor qu√© era necesaria esta arquitectura?

### Limitaciones de arquitecturas previas (RNN, LSTM):

- Procesaban las secuencias de forma **lineal paso a paso**, lo que dificultaba el paralelismo y la escalabilidad.
- Dificultades para **aprender relaciones a largo plazo** en secuencias largas (problema del gradiente).
- Alto costo de entrenamiento en tareas multiling√ºes o multisentencia.

### Ventajas del Transformer:

- **Paralelizaci√≥n completa:** permite procesar todos los tokens a la vez.
- **Self-attention:** capta relaciones de dependencia entre palabras **sin importar la distancia** en la secuencia.
- Escalable: permite modelos de **miles de millones de par√°metros** con entrenamiento distribuido.
- Modular: sirve para tareas muy diversas (clasificaci√≥n, generaci√≥n, resumen, traducci√≥n).

---

## üéØ Aplicaciones objetivo

- **Procesamiento de lenguaje natural (NLP):** traducci√≥n autom√°tica, chatbots, an√°lisis de sentimientos, generaci√≥n de texto, respuesta a preguntas.
- **Visi√≥n por computadora:** clasificaci√≥n de im√°genes, generaci√≥n visual (ViT, DALL¬∑E).
- **C√≥digo y matem√°ticas:** modelos como Codex o AlphaCode generan c√≥digo fuente desde lenguaje natural.
- **Audio y m√∫sica:** modelos como Whisper procesan audio y reconocen voz multiling√ºe.
- **Ciencias biol√≥gicas:** AlphaFold usa arquitecturas derivadas para predecir estructuras de prote√≠nas.

---

## üß¨ ¬øC√≥mo funciona un Transformer? (vista simplificada)

1. Convierte una secuencia de entrada (palabras, p√≠xeles, etc.) en una representaci√≥n vectorial (*embedding*).
2. Usa capas de **self-attention**, donde cada parte de la secuencia se compara con las dem√°s para determinar su relevancia relativa.
3. Aplica capas de normalizaci√≥n, proyecci√≥n y funciones no lineales.
4. Genera una representaci√≥n procesada (codificada o decodificada) para realizar la tarea deseada.

---

## üèóÔ∏è Otras arquitecturas alternativas (pasadas o emergentes)

| Arquitectura         | Descripci√≥n breve | Limitaciones / comparaci√≥n |
|----------------------|-------------------|-----------------------------|
| **RNN (Recurrent Neural Network)** | Procesa secuencias paso a paso | No paralelizable; memoria corta |
| **LSTM (Long Short-Term Memory)** | Variante mejorada de RNN | Mejor memoria, pero entrenamiento lento |
| **GRU (Gated Recurrent Unit)** | Simplificaci√≥n del LSTM | Similar rendimiento con menos par√°metros |
| **CNN (Convolutional Neural Network)** | Muy usada en visi√≥n y texto corto | Menor capacidad de representaci√≥n jer√°rquica |
| **Perceptr√≥n multicapa (MLP)** | Base hist√≥rica de las redes neuronales | No capta estructura secuencial |
| **Retentive Network / Mamba (2023‚Äì2024)** | Nuevas arquitecturas sin atenci√≥n | Buscan eficiencia a gran escala |

---

## üß† Reflexi√≥n final

La arquitectura Transformer representa un **cambio de paradigma**: no solo mejor√≥ el rendimiento, sino que tambi√©n desbloque√≥ una nueva era de modelos de lenguaje y multimodales. Gracias a su flexibilidad y escalabilidad, se ha vuelto la columna vertebral de los sistemas de IA m√°s avanzados de la actualidad.

> **"Attention" ya no es solo una t√©cnica: es la clave de una nueva forma de aprendizaje distribuido.**

---



## üöÄ VI. Estado actual y perspectivas
Predominio de modelos grandes de lenguaje (LLMs): razonamiento, codificaci√≥n, traducci√≥n.

Desarrollo de IA multimodal (texto, imagen, voz).

Desaf√≠os en √©tica, transparencia, alineamiento y regulaci√≥n.

A√∫n no se alcanza una IA general, pero las aplicaciones son cada vez m√°s amplias e impactantes.

## üìé Recursos sugeridos
Documental: AlphaGo: The Movie (DeepMind, 2017)

Video introductorio (EDteam): ¬øQu√© es y c√≥mo funciona la IA?
