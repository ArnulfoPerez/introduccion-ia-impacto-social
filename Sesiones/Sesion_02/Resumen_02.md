# ğŸ§  Resumen Ejecutivo â€“ SesiÃ³n 2
Historia y taxonomÃ­a de la IA: de la cibernÃ©tica a la explosiÃ³n algorÃ­tmica

## ğŸ¯ Objetivo de la sesiÃ³n
Comprender el desarrollo histÃ³rico y filosÃ³fico de la inteligencia artificial (IA), identificar sus principales categorÃ­as funcionales y algorÃ­tmicas, y reconocer los hitos culturales, tÃ©cnicos e institucionales que marcaron su evoluciÃ³n.

## ğŸ•°ï¸ I. Trayectoria histÃ³rica de la IA
Pioneros y contexto fundacional (dÃ©cadas 1940â€“1950)
Alan Turing propuso la idea de una mÃ¡quina que piense, introduciendo la prueba de Turing (1950).

Norbert Wiener, junto con Arturo Rosenblueth, desarrollÃ³ la cibernÃ©tica: estudio de sistemas que se autorregulan mediante retroalimentaciÃ³n.

El surgimiento de la IA estuvo vinculado a avances tÃ©cnicos de posguerra, optimismo cientÃ­fico y la metÃ¡fora computacional de la mente.

Conferencia de Dartmouth (1956)
Marca el inicio formal del campo de la IA.

Principales figuras: John McCarthy, Marvin Minsky, Claude Shannon, Herbert Simon, Allen Newell.

Expectativas: lograr razonamiento automÃ¡tico, comprensiÃ³n del lenguaje, planificaciÃ³n, e incluso conciencia artificial en pocas dÃ©cadas.

## â„ï¸ II. IA simbÃ³lica y sus lÃ­mites
PredominÃ³ por dÃ©cadas: reglas lÃ³gicas, motores de inferencia, representaciones simbÃ³licas.

Minsky y Papert (1969) demostraron las limitaciones de los perceptrones (modelo neuronal simple), frenando el entusiasmo por las redes neuronales.

Primer invierno de la IA (aÃ±os 70â€“80): desilusiÃ³n ante el estancamiento tÃ©cnico.

## ğŸ“¸ III. Auge del aprendizaje profundo (Deep Learning)
VisiÃ³n artificial y el desafÃ­o de ImageNet
ILSVRC (2010â€“2017): competencia impulsada por Stanford y Princeton para mejorar el reconocimiento visual.

En 2012, AlexNet (Hinton, Krizhevsky, Sutskever) introduce redes profundas con GPU â†’ salto cualitativo en precisiÃ³n.

### AnÃ©cdotas clave
â€œLos gatitos de Ngâ€: red neuronal sin supervisiÃ³n identifica rostros y gatos sin ser entrenada explÃ­citamente.

Google Translate mejora cuando se prescinde de expertos lingÃ¼istas y se entrenan modelos con grandes corpus.

Sam Altman (OpenAI): pasÃ³ de escÃ©ptico a promotor clave tras el Ã©xito inesperado de modelos de lenguaje.

## â™Ÿï¸ IV. Reinforcement Learning y dominio de juegos
IBM Deep Blue (1997) derrota a Kasparov con fuerza bruta + heurÃ­stica.

AlphaGo (DeepMind, 2016) vence a campeones de Go combinando redes profundas y reinforcement learning.

Abre camino a la IA como herramienta de toma de decisiones adaptativas.

## ğŸ§­ V. TaxonomÃ­a de la IA
### A. SegÃºn alcance o capacidad
| Tipo de IA             | DescripciÃ³n                                                                 |
|------------------------|------------------------------------------------------------------------------|
| **Estrecha (narrow)**  | Tareas especÃ­ficas (ej. traducciÃ³n automÃ¡tica, recomendaciÃ³n de productos).  |
| **General (AGI)**      | Capacidad cognitiva similar a la de un ser humano (aÃºn hipotÃ©tica).          |
| **Superinteligente**   | IA hipotÃ©tica que supera a los humanos en todas las Ã¡reas del conocimiento. |

### B. SegÃºn enfoque tÃ©cnico
| Enfoque                   | CaracterÃ­sticas                                                   |
|---------------------------|--------------------------------------------------------------------|
| **SimbÃ³lico (GOFAI)**     | Reglas explÃ­citas y lÃ³gica formal; alta interpretabilidad.         |
| **Aprendizaje automÃ¡tico (ML)** | Modelado estadÃ­stico basado en datos; requiere entrenamiento supervisado o no supervisado. |
| **Aprendizaje profundo (DL)**   | Redes neuronales con muchas capas; detecta representaciones jerÃ¡rquicas complejas.           |
| **Aprendizaje por refuerzo**    | Agentes que aprenden mediante prueba y error optimizando recompensas en un entorno.         |
| **Neuro-simbÃ³lico**             | Combina estructuras simbÃ³licas con redes neuronales; busca razonamiento interpretable con flexibilidad adaptativa. |

> ğŸ“Œ Deep Learning es un subcampo dentro del ML, que a su vez es una rama dentro de la IA.

# ğŸ§­ TaxonomÃ­a tÃ©cnica ampliada de la Inteligencia Artificial

Esta tabla resume cÃ³mo se ubican algunos enfoques y tÃ©cnicas contemporÃ¡neas dentro de la arquitectura general de la IA.

---

## ğŸ“š ClasificaciÃ³n general

| Enfoque tÃ©cnico               | SubcategorÃ­as / Ejemplos clave                                            |
|-------------------------------|----------------------------------------------------------------------------|
| **IA simbÃ³lica (GOFAI)**      | Sistemas expertos, lÃ³gica formal, planificaciÃ³n automÃ¡tica                |
| **Aprendizaje automÃ¡tico (ML)** | Supervisado / No supervisado / Semi-supervisado                         |
| â†’ **Aprendizaje profundo (DL)** | CNNs (visiÃ³n), RNNs (texto), Transformers                               |
|    â†’ **LLMs (Large Language Models)** | GPT, BERT, LLaMA, PaLM (basados en Transformers)               |
| **Aprendizaje por refuerzo (RL)** | Q-learning, SARSA, polÃ­ticas adaptativas                               |
| â†’ **Deep RL**                 | AlphaGo, AlphaZero, Codex, robÃ³tica autÃ³noma                             |
| **Neuro-simbÃ³lico**           | Redes neuronales + reglas estructuradas; razonamiento interpretativo      |

---

## ğŸ” UbicaciÃ³n especÃ­fica

- **LLMs (Large Language Models)**  
  - Subtipo de **Aprendizaje profundo (DL)**  
  - Usan arquitectura **Transformer**  
  - Entrenamiento auto-supervisado con grandes corpus de texto  
  - Ejemplos: GPT, Claude, BERT, LLaMA, Gemini

- **Reinforcement Learning (RL)**  
  - Enfoque distinto al aprendizaje supervisado  
  - El agente aprende por ensayo y error en un entorno dinÃ¡mico  
  - Usado en juegos, navegaciÃ³n, robÃ³tica, optimizaciÃ³n de procesos  
  - **Deep RL** combina RL con redes neuronales profundas para tareas complejas

---

## ğŸ¤– AnalogÃ­a conceptual

- **LLMs**: â€œAprenden leyendo libros, textos y conversacionesâ€ â†’ uso masivo de texto digital
- **RL**: â€œAprende actuando y cometiendo erroresâ€ â†’ agente adaptativo que explora su entorno

---

# âš™ï¸ Â¿QuÃ© es la arquitectura Transformer?

La arquitectura **Transformer** es un tipo de modelo de red neuronal profunda diseÃ±ado para procesar secuencias de datos (como texto, audio o cÃ³digo) de forma eficiente y paralela. Se ha convertido en la **base tÃ©cnica dominante** para modelos de lenguaje natural como GPT, BERT, T5, LLaMA y Gemini, asÃ­ como para aplicaciones en visiÃ³n, traducciÃ³n automÃ¡tica, mÃºsica, proteÃ­nas y mÃ¡s.

---

## ğŸ“œ Origen: Â¿QuiÃ©n la propuso y por quÃ©?

- Fue introducida en 2017 por investigadores de Google Brain en el artÃ­culo seminal titulado  
  **"Attention is All You Need"** (*Vaswani et al., 2017*).
- Su motivaciÃ³n fue reemplazar arquitecturas anteriores â€”como las redes recurrentes (RNN) y LSTMâ€” que eran lentas y difÃ­ciles de paralelizar.

> âœ… La clave de los Transformers es su mecanismo de **self-attention**, que permite al modelo enfocarse dinÃ¡micamente en distintas partes de una secuencia al mismo tiempo.

---

## ğŸ§  Â¿Por quÃ© era necesaria esta arquitectura?

### Limitaciones de arquitecturas previas (RNN, LSTM):

- Procesaban las secuencias de forma **lineal paso a paso**, lo que dificultaba el paralelismo y la escalabilidad.
- Dificultades para **aprender relaciones a largo plazo** en secuencias largas (problema del gradiente).
- Alto costo de entrenamiento en tareas multilingÃ¼es o multisentencia.

### Ventajas del Transformer:

- **ParalelizaciÃ³n completa:** permite procesar todos los tokens a la vez.
- **Self-attention:** capta relaciones de dependencia entre palabras **sin importar la distancia** en la secuencia.
- Escalable: permite modelos de **miles de millones de parÃ¡metros** con entrenamiento distribuido.
- Modular: sirve para tareas muy diversas (clasificaciÃ³n, generaciÃ³n, resumen, traducciÃ³n).

---

## ğŸ¯ Aplicaciones objetivo

- **Procesamiento de lenguaje natural (NLP):** traducciÃ³n automÃ¡tica, chatbots, anÃ¡lisis de sentimientos, generaciÃ³n de texto, respuesta a preguntas.
- **VisiÃ³n por computadora:** clasificaciÃ³n de imÃ¡genes, generaciÃ³n visual (ViT, DALLÂ·E).
- **CÃ³digo y matemÃ¡ticas:** modelos como Codex o AlphaCode generan cÃ³digo fuente desde lenguaje natural.
- **Audio y mÃºsica:** modelos como Whisper procesan audio y reconocen voz multilingÃ¼e.
- **Ciencias biolÃ³gicas:** AlphaFold usa arquitecturas derivadas para predecir estructuras de proteÃ­nas.

---

## ğŸ§¬ Â¿CÃ³mo funciona un Transformer? (vista simplificada)

1. Convierte una secuencia de entrada (palabras, pÃ­xeles, etc.) en una representaciÃ³n vectorial (*embedding*).
2. Usa capas de **self-attention**, donde cada parte de la secuencia se compara con las demÃ¡s para determinar su relevancia relativa.
3. Aplica capas de normalizaciÃ³n, proyecciÃ³n y funciones no lineales.
4. Genera una representaciÃ³n procesada (codificada o decodificada) para realizar la tarea deseada.

---

## ğŸ—ï¸ Otras arquitecturas alternativas (pasadas o emergentes)

| Arquitectura         | DescripciÃ³n breve | Limitaciones / comparaciÃ³n |
|----------------------|-------------------|-----------------------------|
| **RNN (Recurrent Neural Network)** | Procesa secuencias paso a paso | No paralelizable; memoria corta |
| **LSTM (Long Short-Term Memory)** | Variante mejorada de RNN | Mejor memoria, pero entrenamiento lento |
| **GRU (Gated Recurrent Unit)** | SimplificaciÃ³n del LSTM | Similar rendimiento con menos parÃ¡metros |
| **CNN (Convolutional Neural Network)** | Muy usada en visiÃ³n y texto corto | Menor capacidad de representaciÃ³n jerÃ¡rquica |
| **PerceptrÃ³n multicapa (MLP)** | Base histÃ³rica de las redes neuronales | No capta estructura secuencial |
| **Retentive Network / Mamba (2023â€“2024)** | Nuevas arquitecturas sin atenciÃ³n | Buscan eficiencia a gran escala |

---

## ğŸ§  ReflexiÃ³n final

La arquitectura Transformer representa un **cambio de paradigma**: no solo mejorÃ³ el rendimiento, sino que tambiÃ©n desbloqueÃ³ una nueva era de modelos de lenguaje y multimodales. Gracias a su flexibilidad y escalabilidad, se ha vuelto la columna vertebral de los sistemas de IA mÃ¡s avanzados de la actualidad.

> **"Attention" ya no es solo una tÃ©cnica: es la clave de una nueva forma de aprendizaje distribuido.**

---



## ğŸš€ VI. Estado actual y perspectivas
Predominio de modelos grandes de lenguaje (LLMs): razonamiento, codificaciÃ³n, traducciÃ³n.

Desarrollo de IA multimodal (texto, imagen, voz).

DesafÃ­os en Ã©tica, transparencia, alineamiento y regulaciÃ³n.

AÃºn no se alcanza una IA general, pero las aplicaciones son cada vez mÃ¡s amplias e impactantes.

## ğŸ“ Recursos sugeridos
Documental: AlphaGo: The Movie (DeepMind, 2017)

Video introductorio (EDteam): Â¿QuÃ© es y cÃ³mo funciona la IA?
